{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition: Digit Recognizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Digit Recognizer Competition](https://www.kaggle.com/c/digit-recognizer)\n",
    "\n",
    "> MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for > benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "> In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 24\n",
    "img_rows, img_columns = 28, 28\n",
    "input_shape = (img_rows, img_columns, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the train and test datasets using Kaggle API:\n",
    "\n",
    "```\n",
    "$ kaggle competitions download digit-recognizer \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv('train.csv', sep=',')\n",
    "train_data = train_dataframe.values\n",
    "\n",
    "test_dataframe = pd.read_csv('test.csv', sep=',')\n",
    "test_data = test_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshapes training and validation data to a third-order degree\n",
    "# Since MNIST is composed of grayscale images, just one channel is needed\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_columns, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_columns, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_columns, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures arrays are float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures data have zero-mean\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28, 1)\n",
      "(8400, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n",
      "(33600,)\n",
      "(8400,)\n"
     ]
    }
   ],
   "source": [
    "# Checks arrays dimensions\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glauco/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# One-hot encodes output to get multiclass classification using softmax \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "33600/33600 [==============================] - 32s 947us/step - loss: 0.1794 - acc: 0.9433\n",
      "Epoch 2/24\n",
      "33600/33600 [==============================] - 32s 951us/step - loss: 0.0534 - acc: 0.9843\n",
      "Epoch 3/24\n",
      "33600/33600 [==============================] - 29s 873us/step - loss: 0.0385 - acc: 0.9885\n",
      "Epoch 4/24\n",
      "33600/33600 [==============================] - 32s 965us/step - loss: 0.0288 - acc: 0.9908\n",
      "Epoch 5/24\n",
      "33600/33600 [==============================] - 33s 987us/step - loss: 0.0215 - acc: 0.9933\n",
      "Epoch 6/24\n",
      "33600/33600 [==============================] - 31s 926us/step - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 7/24\n",
      "33600/33600 [==============================] - 31s 926us/step - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 8/24\n",
      "33600/33600 [==============================] - 32s 954us/step - loss: 0.0130 - acc: 0.9962\n",
      "Epoch 9/24\n",
      "33600/33600 [==============================] - 36s 1ms/step - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 10/24\n",
      "33600/33600 [==============================] - 32s 949us/step - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 11/24\n",
      "33600/33600 [==============================] - 33s 968us/step - loss: 0.0073 - acc: 0.9978\n",
      "Epoch 12/24\n",
      "33600/33600 [==============================] - 31s 927us/step - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 13/24\n",
      "33600/33600 [==============================] - 31s 931us/step - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 14/24\n",
      "33600/33600 [==============================] - 31s 925us/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 15/24\n",
      "33600/33600 [==============================] - 31s 936us/step - loss: 0.0063 - acc: 0.9985\n",
      "Epoch 16/24\n",
      "33600/33600 [==============================] - 31s 937us/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 17/24\n",
      "33600/33600 [==============================] - 31s 932us/step - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 18/24\n",
      "33600/33600 [==============================] - 31s 933us/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 19/24\n",
      "33600/33600 [==============================] - 31s 927us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 20/24\n",
      "33600/33600 [==============================] - 31s 909us/step - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 21/24\n",
      "33600/33600 [==============================] - 29s 859us/step - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 22/24\n",
      "33600/33600 [==============================] - 29s 874us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 23/24\n",
      "33600/33600 [==============================] - 29s 873us/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 24/24\n",
      "33600/33600 [==============================] - 29s 866us/step - loss: 0.0019 - acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb60809a2e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluates model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 1s 164us/step\n",
      "Validation Loss: 0.04345421865033164\n",
      "Validation accuracy: 0.9922619047619048\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose=1)\n",
    "print('Validation Loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluates model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [np.argmax(predictions[i]) for i in range(predictions.shape[0])]\n",
    "image_ids = range(1, len(labels) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ImageId': image_ids, 'Label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the results using Kaggle API:\n",
    "\n",
    "```\n",
    "$ kaggle competitions submit -f submission.csv -m 'Recognizing digits with Keras and Tensorflow' digit-recognizer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
