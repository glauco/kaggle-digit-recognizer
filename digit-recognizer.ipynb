{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition: Digit Recognizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Digit Recognizer Competition](https://www.kaggle.com/c/digit-recognizer)\n",
    "\n",
    "> MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for > benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "> In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "img_rows, img_columns = 28, 28\n",
    "input_shape = (img_rows, img_columns, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the train and test datasets using Kaggle API:\n",
    "\n",
    "```\n",
    "$ kaggle competitions download digit-recognizer \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv('train.csv', sep=',')\n",
    "train_data = train_dataframe.values\n",
    "\n",
    "test_dataframe = pd.read_csv('test.csv', sep=',')\n",
    "test_data = test_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshapes training and validation data to a third-order degree\n",
    "# Since MNIST is composed of grayscale images, just one channel is needed\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_columns, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_columns, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_columns, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures arrays are float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures data have zero-mean\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28, 1)\n",
      "(8400, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n",
      "(33600,)\n",
      "(8400,)\n"
     ]
    }
   ],
   "source": [
    "# Checks arrays dimensions\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glauco/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# One-hot encodes output to get multiclass classification using softmax \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "33600/33600 [==============================] - 28s 841us/step - loss: 0.2440 - acc: 0.9243\n",
      "Epoch 2/12\n",
      "33600/33600 [==============================] - 26s 763us/step - loss: 0.0882 - acc: 0.9742\n",
      "Epoch 3/12\n",
      "33600/33600 [==============================] - 28s 828us/step - loss: 0.0683 - acc: 0.9802\n",
      "Epoch 4/12\n",
      "33600/33600 [==============================] - 27s 803us/step - loss: 0.0576 - acc: 0.9830\n",
      "Epoch 5/12\n",
      "33600/33600 [==============================] - 26s 788us/step - loss: 0.0496 - acc: 0.9851\n",
      "Epoch 6/12\n",
      "33600/33600 [==============================] - 27s 798us/step - loss: 0.0459 - acc: 0.9861\n",
      "Epoch 7/12\n",
      "33600/33600 [==============================] - 26s 781us/step - loss: 0.0417 - acc: 0.9876\n",
      "Epoch 8/12\n",
      "33600/33600 [==============================] - 27s 794us/step - loss: 0.0383 - acc: 0.9886\n",
      "Epoch 9/12\n",
      "33600/33600 [==============================] - 26s 765us/step - loss: 0.0413 - acc: 0.9877\n",
      "Epoch 10/12\n",
      "33600/33600 [==============================] - 26s 768us/step - loss: 0.0383 - acc: 0.9886\n",
      "Epoch 11/12\n",
      "33600/33600 [==============================] - 26s 768us/step - loss: 0.0351 - acc: 0.9895\n",
      "Epoch 12/12\n",
      "33600/33600 [==============================] - 26s 782us/step - loss: 0.0346 - acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81094199e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluates model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 1s 144us/step\n",
      "Validation Loss: 0.045616205896839714\n",
      "Validation accuracy: 0.9891666666666666\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose=1)\n",
    "print('Validation Loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluates model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [np.argmax(predictions[i]) for i in range(predictions.shape[0])]\n",
    "image_ids = range(1, len(labels) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ImageId': image_ids, 'Label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the results using Kaggle API:\n",
    "\n",
    "```\n",
    "$ kaggle competitions submit -f submission.csv -m 'Recognizing digits with Keras and Tensorflow' digit-recognizer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
